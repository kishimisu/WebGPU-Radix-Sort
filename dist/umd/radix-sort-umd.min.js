!function(e,r){"object"==typeof exports&&"undefined"!=typeof module?r(exports):"function"==typeof define&&define.amd?define(["exports"],r):r((e="undefined"!=typeof globalThis?globalThis:e||self).RadixSort={})}(this,(function(e){"use strict";function r(e,r){(null==r||r>e.length)&&(r=e.length);for(var i=0,t=Array(r);i<r;i++)t[i]=e[i];return t}function i(e,r){if(!(e instanceof r))throw new TypeError("Cannot call a class as a function")}function t(e,r){for(var i=0;i<r.length;i++){var t=r[i];t.enumerable=t.enumerable||!1,t.configurable=!0,"value"in t&&(t.writable=!0),Object.defineProperty(e,o(t.key),t)}}function n(e,r,i){return r&&t(e.prototype,r),i&&t(e,i),Object.defineProperty(e,"prototype",{writable:!1}),e}function s(e){return function(e){if(Array.isArray(e))return r(e)}(e)||function(e){if("undefined"!=typeof Symbol&&null!=e[Symbol.iterator]||null!=e["@@iterator"])return Array.from(e)}(e)||function(e,i){if(e){if("string"==typeof e)return r(e,i);var t={}.toString.call(e).slice(8,-1);return"Object"===t&&e.constructor&&(t=e.constructor.name),"Map"===t||"Set"===t?Array.from(e):"Arguments"===t||/^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(t)?r(e,i):void 0}}(e)||function(){throw new TypeError("Invalid attempt to spread non-iterable instance.\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.")}()}function o(e){var r=function(e,r){if("object"!=typeof e||!e)return e;var i=e[Symbol.toPrimitive];if(void 0!==i){var t=i.call(e,r||"default");if("object"!=typeof t)return t;throw new TypeError("@@toPrimitive must return a primitive value.")}return("string"===r?String:Number)(e)}(e,"string");return"symbol"==typeof r?r:r+""}function a(e,r){var i={x:r,y:1};if(r>e.limits.maxComputeWorkgroupsPerDimension){var t=Math.floor(Math.sqrt(r)),n=Math.ceil(r/t);i.x=t,i.y=n}return i}function u(e){var r=e.device,i=e.label,t=e.data,n=e.usage,s=void 0===n?0:n,o=r.createBuffer({label:i,usage:s,size:4*t.length,mappedAtCreation:!0});return new Uint32Array(o.getMappedRange()).set(t),o.unmap(),o}var _=function(){return n((function e(r){var t=r.device,n=r.data,s=r.count,o=r.workgroup_size,a=void 0===o?{x:16,y:16}:o,u=r.avoid_bank_conflicts,_=void 0!==u&&u;if(i(this,e),this.device=t,this.workgroup_size=a,this.threads_per_workgroup=a.x*a.y,this.items_per_workgroup=2*this.threads_per_workgroup,Math.log2(this.threads_per_workgroup)%1!=0)throw new Error("workgroup_size.x * workgroup_size.y must be a power of two. (current: ".concat(this.threads_per_workgroup,")"));this.pipelines=[],this.shaderModule=this.device.createShaderModule({label:"prefix-sum",code:_?"\n\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ITEMS_PER_WORKGROUP: u32;\n\nconst NUM_BANKS: u32 = 32;\nconst LOG_NUM_BANKS: u32 = 5;\n\nfn get_offset(offset: u32) -> u32 {\n    // return offset >> LOG_NUM_BANKS; // Conflict-free\n    return (offset >> NUM_BANKS) + (offset >> (2 * LOG_NUM_BANKS)); // Zero bank conflict\n}\n\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn reduce_downsweep(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n    \n    let ELM_TID = TID * 2; // Element pair local ID\n    let ELM_GID = GID * 2; // Element pair global ID\n    \n    // Load input to shared memory\n    let ai: u32 = TID;\n    let bi: u32 = TID + (ITEMS_PER_WORKGROUP >> 1);\n    let s_ai = ai + get_offset(ai);\n    let s_bi = bi + get_offset(bi);\n    let g_ai = ai + WID * 2;\n    let g_bi = bi + WID * 2;\n    temp[s_ai] = items[g_ai];\n    temp[s_bi] = items[g_bi];\n\n    var offset: u32 = 1;\n\n    // Up-sweep (reduce) phase\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            ai += get_offset(ai);\n            bi += get_offset(bi);\n            temp[bi] += temp[ai];\n        }\n\n        offset *= 2;\n    }\n\n    // Save workgroup sum and clear last element\n    if (TID == 0) {\n        var last_offset = ITEMS_PER_WORKGROUP - 1;\n        last_offset += get_offset(last_offset);\n\n        blockSums[WORKGROUP_ID] = temp[last_offset];\n        temp[last_offset] = 0;\n    }\n\n    // Down-sweep phase\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\n        offset >>= 1;\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            ai += get_offset(ai);\n            bi += get_offset(bi);\n\n            let t: u32 = temp[ai];\n            temp[ai] = temp[bi];\n            temp[bi] += t;\n        }\n    }\n    workgroupBarrier();\n\n    // Copy result from shared memory to global memory\n    items[g_ai] = temp[s_ai];\n    items[g_bi] = temp[s_bi];\n}\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn add_block_sums(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    let ELM_ID = GID * 2;\n    let blockSum = blockSums[WORKGROUP_ID];\n\n    items[ELM_ID] += blockSum;\n    items[ELM_ID + 1] += blockSum;\n}":"\n\n@group(0) @binding(0) var<storage, read_write> items: array<u32>;\n@group(0) @binding(1) var<storage, read_write> blockSums: array<u32>;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ITEMS_PER_WORKGROUP: u32;\n\nvar<workgroup> temp: array<u32, ITEMS_PER_WORKGROUP*2>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn reduce_downsweep(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n    \n    let ELM_TID = TID * 2; // Element pair local ID\n    let ELM_GID = GID * 2; // Element pair global ID\n    \n    // Load input to shared memory\n    temp[ELM_TID]     = items[ELM_GID];\n    temp[ELM_TID + 1] = items[ELM_GID + 1];\n\n    var offset: u32 = 1;\n\n    // Up-sweep (reduce) phase\n    for (var d: u32 = ITEMS_PER_WORKGROUP >> 1; d > 0; d >>= 1) {\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n            temp[bi] += temp[ai];\n        }\n\n        offset *= 2;\n    }\n\n    // Save workgroup sum and clear last element\n    if (TID == 0) {\n        let last_offset = ITEMS_PER_WORKGROUP - 1;\n\n        blockSums[WORKGROUP_ID] = temp[last_offset];\n        temp[last_offset] = 0;\n    }\n\n    // Down-sweep phase\n    for (var d: u32 = 1; d < ITEMS_PER_WORKGROUP; d *= 2) {\n        offset >>= 1;\n        workgroupBarrier();\n\n        if (TID < d) {\n            var ai: u32 = offset * (ELM_TID + 1) - 1;\n            var bi: u32 = offset * (ELM_TID + 2) - 1;\n\n            let t: u32 = temp[ai];\n            temp[ai] = temp[bi];\n            temp[bi] += t;\n        }\n    }\n    workgroupBarrier();\n\n    // Copy result from shared memory to global memory\n    items[ELM_GID]     = temp[ELM_TID];\n    items[ELM_GID + 1] = temp[ELM_TID + 1];\n}\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn add_block_sums(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n    \n\n    let ELM_ID = GID * 2;\n    let blockSum = blockSums[WORKGROUP_ID];\n\n    items[ELM_ID] += blockSum;\n    items[ELM_ID + 1] += blockSum;\n}"}),this.create_pass_recursive(n,s)}),[{key:"create_pass_recursive",value:function(e,r){var i=Math.ceil(r/this.items_per_workgroup),t=a(this.device,i),n=this.device.createBuffer({label:"prefix-sum-block-sum",size:4*i,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),s=this.device.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]}),o=this.device.createBindGroup({label:"prefix-sum-bind-group",layout:s,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:n}}]}),u=this.device.createPipelineLayout({bindGroupLayouts:[s]}),_=this.device.createComputePipeline({label:"prefix-sum-scan-pipeline",layout:u,compute:{module:this.shaderModule,entryPoint:"reduce_downsweep",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ITEMS_PER_WORKGROUP:this.items_per_workgroup}}});if(this.pipelines.push({pipeline:_,bindGroup:o,dispatchSize:t}),i>1){this.create_pass_recursive(n,i);var f=this.device.createComputePipeline({label:"prefix-sum-add-block-pipeline",layout:u,compute:{module:this.shaderModule,entryPoint:"add_block_sums",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,THREADS_PER_WORKGROUP:this.threads_per_workgroup}}});this.pipelines.push({pipeline:f,bindGroup:o,dispatchSize:t})}}},{key:"get_dispatch_chain",value:function(){return this.pipelines.flatMap((function(e){return[e.dispatchSize.x,e.dispatchSize.y,1]}))}},{key:"dispatch",value:function(e,r){for(var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=0;t<this.pipelines.length;t++){var n=this.pipelines[t],s=n.pipeline,o=n.bindGroup;e.setPipeline(s),e.setBindGroup(0,o),e.dispatchWorkgroupsIndirect(r,i+3*t*4)}}}])}(),f="\n\n@group(0) @binding(0) var<storage, read> inputKeys: array<u32>;\n@group(0) @binding(1) var<storage, read_write> outputKeys: array<u32>;\n@group(0) @binding(2) var<storage, read> local_prefix_sum: array<u32>;\n@group(0) @binding(3) var<storage, read> prefix_block_sum: array<u32>;\n@group(0) @binding(4) var<storage, read> inputValues: array<u32>;\n@group(0) @binding(5) var<storage, read_write> outputValues: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort_reorder(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) { \n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    if (GID >= ELEMENT_COUNT) {\n        return;\n    }\n\n    let k = inputKeys[GID];\n    let v = inputValues[GID];\n\n    let local_prefix = local_prefix_sum[GID];\n\n    // Calculate new position\n    let extract_bits = (k >> CURRENT_BIT) & 0x3;\n    let pid = extract_bits * WORKGROUP_COUNT + WORKGROUP_ID;\n    let sorted_position = prefix_block_sum[pid] + local_prefix;\n    \n    outputKeys[sorted_position] = k;\n    outputValues[sorted_position] = v;\n}",l=function(){var e=arguments.length>1&&void 0!==arguments[1]&&arguments[1],r=arguments.length>2&&void 0!==arguments[2]&&arguments[2];return"\n\n@group(0) @binding(0) var<storage, read> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> output: array<u32>;\n@group(0) @binding(2) var<storage, read> original: array<u32>;\n@group(0) @binding(3) var<storage, read_write> is_sorted: u32;\n\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride ELEMENT_COUNT: u32;\noverride START_ELEMENT: u32;\n\nvar<workgroup> s_data: array<u32, THREADS_PER_WORKGROUP>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn check_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP + START_ELEMENT;\n    let GID = TID + WID; // Global thread ID\n\n    // Load data into shared memory\n    ".concat(arguments.length>0&&void 0!==arguments[0]&&arguments[0]?c:"s_data[TID] = select(0u, input[GID], GID < ELEMENT_COUNT);","\n\n    // Perform parallel reduction\n    for (var d = 1u; d < THREADS_PER_WORKGROUP; d *= 2u) {      \n        workgroupBarrier();  \n        if (TID % (2u * d) == 0u) {\n            s_data[TID] += s_data[TID + d];\n        }\n    }\n    workgroupBarrier();\n\n    // Write reduction result\n    ").concat(e?d(r):p,"\n}")},p="\n    if (TID == 0) {\n        output[WORKGROUP_ID] = s_data[0];\n    }\n",c="\n    let LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n\n    // Load current element into shared memory\n    // Also load next element for comparison\n    let elm = select(0u, input[GID], GID < ELEMENT_COUNT);\n    let next = select(0u, input[GID + 1], GID < ELEMENT_COUNT-1);\n    s_data[TID] = elm;\n    workgroupBarrier();\n\n    s_data[TID] = select(0u, 1u, GID < ELEMENT_COUNT-1 && elm > next);\n",d=function(e){return"\n    let fullDispatchLength = arrayLength(&output);\n    let dispatchIndex = TID * 3;\n\n    if (dispatchIndex >= fullDispatchLength) {\n        return;\n    }\n\n    ".concat(e?b:h,"\n")},h="\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] == 0 && is_sorted == 0u);\n",b="\n    if (TID == 0 && s_data[0] == 0) {\n        is_sorted = 1u;\n    }\n\n    output[dispatchIndex] = select(0, original[dispatchIndex], s_data[0] != 0);\n",O=function(){return n((function e(r){var t=r.device,n=r.data,s=r.result,o=r.original,a=r.is_sorted,u=r.count,_=r.start,f=void 0===_?0:_,l=r.full_check,p=void 0===l||l,c=r.workgroup_size,d=void 0===c?{x:16,y:16}:c;i(this,e),this.device=t,this.count=u,this.start=f,this.full_check=p,this.workgroup_size=d,this.threads_per_workgroup=d.x*d.y,this.pipelines=[],this.buffers={data:n,result:s,original:o,is_sorted:a,outputs:[]},this.create_passes_recursive(n,u)}),[{key:"create_passes_recursive",value:function(e,r){var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=Math.ceil(r/this.threads_per_workgroup),n=0===i,o=t<=1,a=o?this.buffers.result:this.device.createBuffer({label:"check-sort-".concat(this.full_check?"full":"fast","-").concat(i),size:4*t,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),u=this.device.createBindGroupLayout({entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}].concat(s(o?[{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),_=this.device.createBindGroup({layout:u,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:a}}].concat(s(o?[{binding:2,resource:{buffer:this.buffers.original}},{binding:3,resource:{buffer:this.buffers.is_sorted}}]:[]))}),f=this.device.createPipelineLayout({bindGroupLayouts:[u]}),p=n?this.start+r:r,c=n?this.start:0,d=this.device.createComputePipeline({layout:f,compute:{module:this.device.createShaderModule({code:l(n,o,this.full_check),label:"check-sort"}),entryPoint:"check_sort",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:p,START_ELEMENT:c}}});this.buffers.outputs.push(a),this.pipelines.push({pipeline:d,bindGroup:_}),o||this.create_passes_recursive(a,t,i+1)}},{key:"dispatch",value:function(e,r){for(var i=arguments.length>2&&void 0!==arguments[2]?arguments[2]:0,t=0;t<this.pipelines.length;t++){var n=this.pipelines[t],s=n.pipeline,o=n.bindGroup,a=this.full_check||t<this.pipelines.length-1;e.setPipeline(s),e.setBindGroup(0,o),a?e.dispatchWorkgroupsIndirect(r,i+3*t*4):e.dispatchWorkgroups(1,1,1)}}}],[{key:"find_optimal_dispatch_chain",value:function(e,r,i){var t=i.x*i.y,n=[];do{var s=Math.ceil(r/t),o=a(e,s);n.push(o.x,o.y,1),r=s}while(r>1);return n}}])}(),g=function(){return n((function e(){var r=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},t=r.device,n=r.keys,s=r.values,o=r.count,u=r.bit_count,_=void 0===u?32:u,f=r.workgroup_size,l=void 0===f?{x:16,y:16}:f,p=r.check_order,c=void 0!==p&&p,d=r.local_shuffle,h=void 0!==d&&d,b=r.avoid_bank_conflicts,O=void 0!==b&&b;if(i(this,e),null==t)throw new Error("No device provided");if(null==n)throw new Error("No keys buffer provided");if(!Number.isInteger(o)||o<=0)throw new Error("Invalid count parameter");if(!Number.isInteger(_)||_<=0||_>32)throw new Error("Invalid bit_count parameter");if(!Number.isInteger(l.x)||!Number.isInteger(l.y))throw new Error("Invalid workgroup_size parameter");if(_%4!=0)throw new Error("bit_count must be a multiple of 4");this.device=t,this.count=o,this.bit_count=_,this.workgroup_size=l,this.check_order=c,this.local_shuffle=h,this.avoid_bank_conflicts=O,this.threads_per_workgroup=l.x*l.y,this.workgroup_count=Math.ceil(o/this.threads_per_workgroup),this.prefix_block_workgroup_count=4*this.workgroup_count,this.has_values=null!=s,this.dispatchSize={},this.shaderModules={},this.buffers={},this.pipelines=[],this.kernels={},this.dispatchSize=a(this.device,this.workgroup_count),this.create_shader_modules(),this.create_pipelines(n,s)}),[{key:"create_shader_modules",value:function(){var e=function(e){return e.split("\n").filter((function(e){return!e.toLowerCase().includes("values")})).join("\n")},r=this.local_shuffle?"\n\n@group(0) @binding(0) var<storage, read_write> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\n@group(0) @binding(3) var<storage, read_write> values: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\nvar<workgroup> s_prefix_sum_scan: array<u32, 4>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    // Extract 2 bits from the input\n    let elm = input[GID];\n    let val = values[GID];\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\n\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\n\n    // If the workgroup is inactive, prevent block_sums buffer update\n    var LAST_THREAD: u32 = 0xffffffff; \n\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\n        // Otherwise store the index of the last active thread in the workgroup\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n    }\n\n    // Initialize parameters for double-buffering\n    let TPW = THREADS_PER_WORKGROUP + 1;\n    var swapOffset: u32 = 0;\n    var inOffset:  u32 = TID;\n    var outOffset: u32 = TID + TPW;\n\n    // 4-way prefix sum\n    for (var b: u32 = 0; b < 4; b++) {\n        // Initialize local prefix with bitmask\n        let bitmask = select(0u, 1u, extract_bits == b);\n        s_prefix_sum[inOffset + 1] = bitmask;\n        workgroupBarrier();\n\n        // Prefix sum\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\n            if (TID >= offset) {\n                s_prefix_sum[outOffset] = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\n            } else {\n                s_prefix_sum[outOffset] = s_prefix_sum[inOffset];\n            }\n\n            // Swap buffers\n            outOffset = inOffset;\n            swapOffset = TPW - swapOffset;\n            inOffset = TID + swapOffset;\n            \n            workgroupBarrier();\n        }\n\n        // Store prefix sum for current bit\n        let prefix_sum = s_prefix_sum[inOffset];\n        bit_prefix_sums[b] = prefix_sum;\n\n        if (TID == LAST_THREAD) {\n            // Store block sum to global memory\n            let total_sum: u32 = prefix_sum + bitmask;\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\n        }\n\n        // Swap buffers\n        outOffset = inOffset;\n        swapOffset = TPW - swapOffset;\n        inOffset = TID + swapOffset;\n    }\n\n    let prefix_sum = bit_prefix_sums[extract_bits];   \n\n    // Scan bit prefix sums\n    if (TID == LAST_THREAD) {\n        var sum: u32 = 0;\n        bit_prefix_sums[extract_bits] += 1;\n        for (var i: u32 = 0; i < 4; i++) {\n            s_prefix_sum_scan[i] = sum;\n            sum += bit_prefix_sums[i];\n        }\n    }\n    workgroupBarrier();\n\n    if (GID < ELEMENT_COUNT) {\n        // Compute new position\n        let new_pos: u32 = prefix_sum + s_prefix_sum_scan[extract_bits];\n\n        // Shuffle elements locally\n        input[WID + new_pos] = elm;\n        values[WID + new_pos] = val;\n        local_prefix_sums[WID + new_pos] = prefix_sum;\n    }\n}":"\n\n@group(0) @binding(0) var<storage, read> input: array<u32>;\n@group(0) @binding(1) var<storage, read_write> local_prefix_sums: array<u32>;\n@group(0) @binding(2) var<storage, read_write> block_sums: array<u32>;\n\noverride WORKGROUP_COUNT: u32;\noverride THREADS_PER_WORKGROUP: u32;\noverride WORKGROUP_SIZE_X: u32;\noverride WORKGROUP_SIZE_Y: u32;\noverride CURRENT_BIT: u32;\noverride ELEMENT_COUNT: u32;\n\nvar<workgroup> s_prefix_sum: array<u32, 2 * (THREADS_PER_WORKGROUP + 1)>;\n\n@compute @workgroup_size(WORKGROUP_SIZE_X, WORKGROUP_SIZE_Y, 1)\nfn radix_sort(\n    @builtin(workgroup_id) w_id: vec3<u32>,\n    @builtin(num_workgroups) w_dim: vec3<u32>,\n    @builtin(local_invocation_index) TID: u32, // Local thread ID\n) {\n    let WORKGROUP_ID = w_id.x + w_id.y * w_dim.x;\n    let WID = WORKGROUP_ID * THREADS_PER_WORKGROUP;\n    let GID = WID + TID; // Global thread ID\n\n    // Extract 2 bits from the input\n    let elm = input[GID];\n    let extract_bits: u32 = (elm >> CURRENT_BIT) & 0x3;\n\n    var bit_prefix_sums = array<u32, 4>(0, 0, 0, 0);\n\n    // If the workgroup is inactive, prevent block_sums buffer update\n    var LAST_THREAD: u32 = 0xffffffff; \n\n    if (WORKGROUP_ID < WORKGROUP_COUNT) {\n        // Otherwise store the index of the last active thread in the workgroup\n        LAST_THREAD = min(THREADS_PER_WORKGROUP, ELEMENT_COUNT - WID) - 1;\n    }\n\n    // Initialize parameters for double-buffering\n    let TPW = THREADS_PER_WORKGROUP + 1;\n    var swapOffset: u32 = 0;\n    var inOffset:  u32 = TID;\n    var outOffset: u32 = TID + TPW;\n\n    // 4-way prefix sum\n    for (var b: u32 = 0; b < 4; b++) {\n        // Initialize local prefix with bitmask\n        let bitmask = select(0u, 1u, extract_bits == b);\n        s_prefix_sum[inOffset + 1] = bitmask;\n        workgroupBarrier();\n\n        // Prefix sum\n        for (var offset: u32 = 1; offset < THREADS_PER_WORKGROUP; offset *= 2) {\n            if (TID >= offset) {\n                s_prefix_sum[outOffset] = s_prefix_sum[inOffset] + s_prefix_sum[inOffset - offset];\n            } else {\n                s_prefix_sum[outOffset] = s_prefix_sum[inOffset];\n            }\n\n            // Swap buffers\n            outOffset = inOffset;\n            swapOffset = TPW - swapOffset;\n            inOffset = TID + swapOffset;\n            \n            workgroupBarrier();\n        }\n\n        // Store prefix sum for current bit\n        let prefix_sum = s_prefix_sum[inOffset];\n        bit_prefix_sums[b] = prefix_sum;\n\n        if (TID == LAST_THREAD) {\n            // Store block sum to global memory\n            let total_sum: u32 = prefix_sum + bitmask;\n            block_sums[b * WORKGROUP_COUNT + WORKGROUP_ID] = total_sum;\n        }\n\n        // Swap buffers\n        outOffset = inOffset;\n        swapOffset = TPW - swapOffset;\n        inOffset = TID + swapOffset;\n    }\n\n    // Store local prefix sum to global memory\n    local_prefix_sums[GID] = bit_prefix_sums[extract_bits];\n}";this.shaderModules={blockSum:this.device.createShaderModule({label:"radix-sort-block-sum",code:this.has_values?r:e(r)}),reorder:this.device.createShaderModule({label:"radix-sort-reorder",code:this.has_values?f:e(f)})}}},{key:"create_pipelines",value:function(e,r){var i=this.create_prefix_sum_kernel(),t=i.prefixSumKernel,n=i.prefixBlockSumBuffer,s=this.calculate_dispatch_sizes(t);this.create_buffers(e,r,n,s),this.create_check_sort_kernels(this.buffers.keys,s);for(var o=0;o<this.bit_count;o+=2){var a=o%4==0,u=a?this.buffers.keys:this.buffers.tmpKeys,_=a?this.buffers.values:this.buffers.tmpValues,f=a?this.buffers.tmpKeys:this.buffers.keys,l=a?this.buffers.tmpValues:this.buffers.values,p=this.create_block_sum_pipeline(u,_,o),c=this.create_reorder_pipeline(u,_,f,l,o);this.pipelines.push({blockSumPipeline:p,reorderPipeline:c})}}},{key:"create_prefix_sum_kernel",value:function(){var e=this.device.createBuffer({label:"radix-sort-prefix-block-sum",size:4*this.prefix_block_workgroup_count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),r=new _({device:this.device,data:e,count:this.prefix_block_workgroup_count,workgroup_size:this.workgroup_size,avoid_bank_conflicts:this.avoid_bank_conflicts});return this.kernels.prefixSum=r,{prefixSumKernel:r,prefixBlockSumBuffer:e}}},{key:"calculate_dispatch_sizes",value:function(e){var r=e.get_dispatch_chain(),i=Math.min(this.count,4*this.threads_per_workgroup),t=this.count-i,n=i-1,o=O.find_optimal_dispatch_chain(this.device,i,this.workgroup_size),a=O.find_optimal_dispatch_chain(this.device,t,this.workgroup_size),u=[this.dispatchSize.x,this.dispatchSize.y,1].concat(s(o.slice(0,3)),s(r));return this.dispatchOffsets={radix_sort:0,check_sort_fast:12,prefix_sum:24},{initialDispatch:u,dispatchSizesFull:a,check_sort_fast_count:i,check_sort_full_count:t,start_full:n}}},{key:"create_buffers",value:function(e,r,i,t){var n=this.device.createBuffer({label:"radix-sort-tmp-keys",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),s=this.has_values?this.device.createBuffer({label:"radix-sort-tmp-values",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}):null,o=this.device.createBuffer({label:"radix-sort-local-prefix-sum",size:4*this.count,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST}),a=u({device:this.device,label:"radix-sort-dispatch-size",data:t.initialDispatch,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.INDIRECT}),_=u({device:this.device,label:"radix-sort-dispatch-size-original",data:t.initialDispatch,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),f=u({label:"check-sort-full-dispatch-size",device:this.device,data:t.dispatchSizesFull,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.INDIRECT}),l=u({label:"check-sort-full-dispatch-size-original",device:this.device,data:t.dispatchSizesFull,usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC}),p=u({label:"is-sorted",device:this.device,data:new Uint32Array([0]),usage:GPUBufferUsage.STORAGE|GPUBufferUsage.COPY_SRC|GPUBufferUsage.COPY_DST});this.buffers={keys:e,values:r,tmpKeys:n,tmpValues:s,localPrefixSum:o,prefixBlockSum:i,dispatchSize:a,originalDispatchSize:_,checkSortFullDispatchSize:f,originalCheckSortFullDispatchSize:l,isSorted:p}}},{key:"create_check_sort_kernels",value:function(e,r){if(!this.check_order)return[null,null];var i=r.check_sort_fast_count,t=r.check_sort_full_count,n=r.start_full,s=new O({device:this.device,data:e,result:this.buffers.dispatchSize,original:this.buffers.originalDispatchSize,is_sorted:this.buffers.isSorted,count:t,start:n,full_check:!0,workgroup_size:this.workgroup_size}),o=new O({device:this.device,data:e,result:this.buffers.checkSortFullDispatchSize,original:this.buffers.originalCheckSortFullDispatchSize,is_sorted:this.buffers.isSorted,count:i,full_check:!1,workgroup_size:this.workgroup_size});if(o.threads_per_workgroup<s.pipelines.length)return console.warn("Warning: workgroup size is too small to enable check sort optimization, disabling..."),this.check_order=!1,[null,null];this.kernels.checkSortFast=o,this.kernels.checkSortFull=s}},{key:"create_block_sum_pipeline",value:function(e,r,i){var t=this.device.createBindGroupLayout({label:"radix-sort-block-sum",entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:this.local_shuffle?"storage":"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}].concat(s(this.local_shuffle&&this.has_values?[{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),n=this.device.createBindGroup({layout:t,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:this.buffers.localPrefixSum}},{binding:2,resource:{buffer:this.buffers.prefixBlockSum}}].concat(s(this.local_shuffle&&this.has_values?[{binding:3,resource:{buffer:r}}]:[]))}),o=this.device.createPipelineLayout({bindGroupLayouts:[t]});return{pipeline:this.device.createComputePipeline({label:"radix-sort-block-sum",layout:o,compute:{module:this.shaderModules.blockSum,entryPoint:"radix_sort",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,WORKGROUP_COUNT:this.workgroup_count,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:this.count,CURRENT_BIT:i}}}),bindGroup:n}}},{key:"create_reorder_pipeline",value:function(e,r,i,t,n){var o=this.device.createBindGroupLayout({label:"radix-sort-reorder",entries:[{binding:0,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:1,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}},{binding:2,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:3,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}}].concat(s(this.has_values?[{binding:4,visibility:GPUShaderStage.COMPUTE,buffer:{type:"read-only-storage"}},{binding:5,visibility:GPUShaderStage.COMPUTE,buffer:{type:"storage"}}]:[]))}),a=this.device.createBindGroup({layout:o,entries:[{binding:0,resource:{buffer:e}},{binding:1,resource:{buffer:i}},{binding:2,resource:{buffer:this.buffers.localPrefixSum}},{binding:3,resource:{buffer:this.buffers.prefixBlockSum}}].concat(s(this.has_values?[{binding:4,resource:{buffer:r}},{binding:5,resource:{buffer:t}}]:[]))}),u=this.device.createPipelineLayout({bindGroupLayouts:[o]});return{pipeline:this.device.createComputePipeline({label:"radix-sort-reorder",layout:u,compute:{module:this.shaderModules.reorder,entryPoint:"radix_sort_reorder",constants:{WORKGROUP_SIZE_X:this.workgroup_size.x,WORKGROUP_SIZE_Y:this.workgroup_size.y,WORKGROUP_COUNT:this.workgroup_count,THREADS_PER_WORKGROUP:this.threads_per_workgroup,ELEMENT_COUNT:this.count,CURRENT_BIT:n}}}),bindGroup:a}}},{key:"dispatch",value:function(e){for(var r=0;r<this.bit_count/2;r++){var i=this.pipelines[r],t=i.blockSumPipeline,n=i.reorderPipeline;this.check_order&&r%2==0&&(this.kernels.checkSortFast.dispatch(e,this.buffers.dispatchSize,this.dispatchOffsets.check_sort_fast),this.kernels.checkSortFull.dispatch(e,this.buffers.checkSortFullDispatchSize)),e.setPipeline(t.pipeline),e.setBindGroup(0,t.bindGroup),e.dispatchWorkgroupsIndirect(this.buffers.dispatchSize,this.dispatchOffsets.radix_sort),this.kernels.prefixSum.dispatch(e,this.buffers.dispatchSize,this.dispatchOffsets.prefix_sum),e.setPipeline(n.pipeline),e.setBindGroup(0,n.bindGroup),e.dispatchWorkgroupsIndirect(this.buffers.dispatchSize,this.dispatchOffsets.radix_sort)}}}])}();e.PrefixSumKernel=_,e.RadixSortKernel=g}));
//# sourceMappingURL=radix-sort-umd.min.js.map
